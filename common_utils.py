# common_utils.py

import torch
import numpy as np
import pandas as pd
from transformers import AutoTokenizer, AutoModelForCausalLM
import re
import json
import os
import warnings
from typing import Dict, List, Tuple, Optional
import random
from torch import nn

# GPUè®¾ç½®
if torch.cuda.is_available():
    device = torch.device('cuda')
    print(f"ğŸš€ Using GPU: {torch.cuda.get_device_name(0)}")
else:
    device = torch.device('cpu')
    print("ğŸ’» Using CPU")

# ========================= æ­¤å¤„ç²˜è´´æ‰€æœ‰å…±äº«çš„ç±»å®šä¹‰ =========================
# ModelConfig, ModelInterface, FixedGSM8KProcessor, ComplexityPredictorNet,
# LearnedAttentionRouter, SLMInterface, EnhancedLLMInterface,
# AccuracyValidator, GSM8KAccuracyEvaluator
#
# æ³¨æ„ï¼šæ‚¨éœ€è¦å°†æˆ‘ä»¬ä¹‹å‰è®¨è®ºè¿‡çš„æ‰€æœ‰ç±»çš„ã€å®Œæ•´ä»£ç ã€‘ç²˜è´´åˆ°è¿™é‡Œã€‚
# ä¸ºä¿æŒæœ¬å›ç­”çš„ç®€æ´æ€§ï¼Œè¿™é‡Œåªå±•ç¤ºä¸€ä¸ªæ¡†æ¶ã€‚
# ========================================================================

class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""

    def __init__(self, name: str, model_path: str, cost_per_token: float, avg_latency_ms: int):
        self.name = name
        self.model_path = model_path
        self.cost_per_token = cost_per_token
        self.avg_latency_ms = avg_latency_ms


class ModelInterface:
    """æ¨¡å‹æ¥å£åŸºç±»"""

    def __init__(self, config: ModelConfig):
        self.config = config
        self.model = None
        self.tokenizer = None

    def predict(self, question: str) -> str:
        raise NotImplementedError


# ========================= GSM8Kæ•°æ®å¤„ç†å™¨ =========================
class FixedGSM8KProcessor:
    """ä¿®å¤ç‰ˆGSM8Kæ•°æ®å¤„ç†å™¨"""

    def __init__(self, data_path="gsm8k_data/train.jsonl", max_samples=1000):
        print(f"ğŸ“š Loading GSM8K dataset...")
        self.data_path = data_path
        self.max_samples = max_samples
        self.samples = []

        # å°è¯•å¤šç§åŠ è½½æ–¹å¼
        if self._load_from_datasets():
            print(f"âœ… Loaded {len(self.samples)} samples from datasets library")
        elif self._load_from_local():
            print(f"âœ… Loaded {len(self.samples)} samples from local file")
        else:
            print("ğŸ”„ Using enhanced fallback data...")
            self.samples = self._create_balanced_fallback()

    def _load_from_datasets(self):
        """ä»datasetsåº“åŠ è½½GSM8K"""
        try:
            from datasets import load_dataset
            print("ğŸ”„ Loading from HuggingFace datasets...")

            # ä½¿ç”¨GSM8Kçš„testé›†ï¼Œå› ä¸ºå®ƒæœ‰æ ‡å‡†ç­”æ¡ˆ
            dataset = load_dataset("gsm8k", "main")
            test_data = dataset['test']

            for i in range(min(self.max_samples, len(test_data))):
                self.samples.append({
                    'question': test_data[i]['question'],
                    'answer': test_data[i]['answer']
                })
            return len(self.samples) > 0
        except Exception as e:
            print(f"âš ï¸ Failed to load from datasets: {e}")
            return False

    def _load_from_local(self):
        """ä»æœ¬åœ°æ–‡ä»¶åŠ è½½"""
        try:
            if not os.path.exists(self.data_path):
                return False

            with open(self.data_path, 'r', encoding='utf-8') as f:
                for line_num, line in enumerate(f, 1):
                    if line.strip():
                        try:
                            data = json.loads(line)
                            self.samples.append({
                                'question': data['question'],
                                'answer': data['answer']
                            })
                            if len(self.samples) >= self.max_samples:
                                break
                        except:
                            continue
            return len(self.samples) > 0
        except:
            return False

    # def _create_balanced_fallback(self):
    #     """åˆ›å»ºå¹³è¡¡çš„åå¤‡æ•°æ®é›†"""
    #     fallback_data = [
    #         {'question': "Janet has 3 apples. She eats 1 apple. How many apples does she have left?",
    #          'answer': "Janet starts with 3 apples.\nShe eats 1 apple.\n3 - 1 = 2\n#### 2"},
    #         {'question': "Tom bought 5 books for $2 each. How much did he spend in total?",
    #          'answer': "Tom bought 5 books.\nEach book costs $2.\n5 Ã— 2 = 10\n#### 10"},
    #         {
    #             'question': "A store sells apples for $3 per kg. If John buys 2.5 kg and pays with a $10 bill, how much change does he get?",
    #             'answer': "Cost per kg: $3\nAmount bought: 2.5 kg\nTotal cost: 3 Ã— 2.5 = $7.50\nPaid: $10\nChange: 10 - 7.50 = $2.50\n#### 2.5"},
    #         {
    #             'question': "A company has 120 employees. 25% work in sales, 30% in engineering, and the rest in administration. If the sales team gets a 15% increase and engineering gets a 10% increase, how many total employees will there be after the increases?",
    #             'answer': "Initial employees: 120\nSales: 25% of 120 = 0.25 Ã— 120 = 30 employees\nEngineering: 30% of 120 = 0.30 Ã— 120 = 36 employees\nAdministration: 120 - 30 - 36 = 54 employees\n\nAfter increases:\nSales increase: 30 Ã— 0.15 = 4.5 â‰ˆ 5 new employees\nEngineering increase: 36 Ã— 0.10 = 3.6 â‰ˆ 4 new employees\n\nTotal after increases: 120 + 5 + 4 = 129 employees\n#### 129"}
    #     ]
    #     print(f"âœ… Created {len(fallback_data)} fallback samples")
    #     return fallback_data

    def extract_answer(self, answer_text: str) -> str:
        """ä»GSM8Kçš„ç­”æ¡ˆæ–‡æœ¬ä¸­æå–æ•°å€¼"""
        match = re.search(r'####\s*([+-]?\d+(?:\.\d+)?)', answer_text)
        if match: return match.group(1)
        numbers = re.findall(r'([+-]?\d+(?:\.\d+)?)', answer_text)
        return numbers[-1] if numbers else "No answer found"

    def count_solution_steps(self, answer: str) -> int:
        """å¤šç»´åº¦æ­¥éª¤è¯†åˆ«ç»¼åˆåˆ¤æ–­æ¨ç†å¤æ‚åº¦"""
        lines = [line.strip() for line in answer.split('\n') if line.strip()]
        meaningful_lines = [line for line in lines if not line.startswith('####')]
        math_operations = len(re.findall(r'\d+\s*[+\-Ã—Ã·*/]\s*\d+', answer))
        equals_count = answer.count('=')
        step_words = len(re.findall(r'\b(then|next|so|therefore|thus|after|now|finally)\b', answer.lower()))
        steps = max(len(meaningful_lines) - 1, math_operations, equals_count, step_words, 1)
        return min(steps, 12)

    def classify_difficulty(self, steps: int) -> str:
        """ä¿®å¤çš„éš¾åº¦åˆ†çº§ - é€‚åº”çœŸå®GSM8Kåˆ†å¸ƒ"""
        if steps <= 4:
            return "simple"
        elif steps <= 8:
            return "medium"
        else:
            return "complex"

    def get_balanced_sample(self, n_total: int = 200, simple_ratio: float = 0.5) -> Tuple[List, List]:
        """è·å–å¹³è¡¡çš„æ ·æœ¬æ•°æ®ï¼ŒæŒ‰æ­¥éª¤æ•°åˆ†ç±»"""
        print(f"ğŸ¯ å‡†å¤‡é‡‡æ · {n_total} é“é¢˜ç›® (ç®€å•é¢˜æ¯”ä¾‹: {simple_ratio:.1%})")
        simple_problems, complex_problems = [], []
        print("ğŸ“‹ æ­£åœ¨åˆ†æé—®é¢˜å¤æ‚åº¦...")
        for i, item in enumerate(self.samples):
            if i % 100 == 0 and i > 0: print(f"   å¤„ç†è¿›åº¦: {i}/{len(self.samples)}")
            problem_data = {'question': item['question'], 'answer': self.extract_answer(item['answer']),
                            'original_answer': item['answer'], 'steps': self.count_solution_steps(item['answer']),
                            'difficulty': self.classify_difficulty(self.count_solution_steps(item['answer']))}
            if problem_data['difficulty'] == "simple":
                simple_problems.append(problem_data)
            else:
                complex_problems.append(problem_data)
        print(f"âœ… åˆ†ç±»å®Œæˆ: {len(simple_problems)} ç®€å•é¢˜, {len(complex_problems)} å¤æ‚é¢˜")
        n_simple, n_complex = int(n_total * simple_ratio), n_total - int(n_total * simple_ratio)
        if len(simple_problems) < n_simple: n_simple = len(simple_problems)
        if len(complex_problems) < n_complex: n_complex = len(complex_problems)
        sampled_simple = random.sample(simple_problems, n_simple) if n_simple > 0 else []
        sampled_complex = random.sample(complex_problems, n_complex) if n_complex > 0 else []
        print(f"ğŸ² æœ€ç»ˆé‡‡æ ·: {len(sampled_simple)} ç®€å•é¢˜, {len(sampled_complex)} å¤æ‚é¢˜")
        return sampled_simple, sampled_complex


class ComplexityPredictorNet(nn.Module):
    """ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œï¼Œç”¨äºä»æ³¨æ„åŠ›ç‰¹å¾ä¸­å­¦ä¹ å¹¶é¢„æµ‹ä»»åŠ¡å¤æ‚åº¦ã€‚"""
    def __init__(self, input_features: int = 8):
        super().__init__()
        self.network = nn.Sequential(
            nn.Linear(input_features, 64), nn.ReLU(), nn.Dropout(0.3),
            nn.Linear(64, 32), nn.ReLU(),
            nn.Linear(32, 1)
        )
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)

class LearnedAttentionRouter:
    # ... (ç²˜è´´å®Œæ•´çš„ç±»å®šä¹‰)
    pass

class GSM8KAccuracyEvaluator:
    # ... (ç²˜è´´å®Œæ•´çš„ç±»å®šä¹‰)
    pass